{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lsLzeYPPKhhe"
      },
      "source": [
        "# OpenCV Guide\n",
        "This is a tool that will utilise the OpenCV image processing tools to collate images and information for data that is present in images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cGoW72d7rxA2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cv2'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61VPhBxSsUDE",
        "outputId": "be3454de-d8ca-48c6-9bd5-1fdacfa6911f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PgGIPZYr2f0"
      },
      "outputs": [],
      "source": [
        "import keras.utils as image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def read_images(path, sz=None):\n",
        "    \"\"\"Reads the images in a given folder, resizes images on the fly if size is given.\n",
        "\n",
        "    Args:\n",
        "        path: Path to a folder with subfolders representing the subjects (persons).\n",
        "        sz: A tuple with the size Resizes\n",
        "\n",
        "    Returns:\n",
        "        A list [X,y]\n",
        "\n",
        "            X: The images, which is a Python list of numpy arrays.\n",
        "            y: The corresponding labels (the unique number of the subject, person) in a Python list.\n",
        "    \"\"\"\n",
        "    c = 0\n",
        "    strerror = ''\n",
        "    errno = 0\n",
        "    X,y = [], []\n",
        "    new_size = (sz, sz)\n",
        "    for dirname, dirnames, filenames in os.walk(path):\n",
        "        for subdirname in dirnames:\n",
        "            subject_path = os.path.join(dirname, subdirname)\n",
        "            for filename in os.listdir(subject_path):\n",
        "                try:\n",
        "                    if (filename == \".directory\"):\n",
        "                        continue\n",
        "                    filepath = os.path.join(subject_path, filename)\n",
        "                    print (filepath)\n",
        "                    im = image.load_img(os.path.join(subject_path, filename))\n",
        "                    \n",
        "                    print(im)\n",
        "                    plt.imshow(im)\n",
        "                    if (im is None):\n",
        "                        print (\"image \" + filepath + \" is none\") \n",
        "                    # resize to given size (if given)\n",
        "                    if (sz is not None):   \n",
        "                        #ref: https://www.geeksforgeeks.org/image-recognition-with-mobilenet/\n",
        "                        res_img = im.resize(new_size)\n",
        "                        # Convert the PIL image to Tensor\n",
        "                        resizedimg = image.img_to_array(res_img)\n",
        "                        finalimg = np.expand_dims(resizedimg,axis=0)\n",
        "                        finalimg = tf.keras.applications.mobilenet_v2.preprocess_input(finalimg)\n",
        "                        finalimg.shape                       \n",
        "\n",
        "                    #X.append(np.asarray(im, dtype=np.uint8))\n",
        "                    X.append(finalimg)\n",
        "                    y.append(c)\n",
        "                # except IOError, (errno, strerror):\n",
        "                #     print (\"I/O error({0}): {1}\".format(errno, strerror))\n",
        "                except:\n",
        "                    print (\"Unexpected error:\", sys.exc_info()[0])\n",
        "                    raise\n",
        "            c = c+1\n",
        "    return [X,y]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnqN3M7Jb1ge"
      },
      "source": [
        "The read_images function expects that the folder structure in the Google Drive has images folder followed by two child folders for two classes (as in the model classification). Therefore, it could be a cat folder and a dog folder for cat| dog classification exercise. \n",
        "\n",
        "Note, it is able to read the child folders automatically. And derive the images from there and place them in X. So, X would contain, 10 cats and 10 dogs images. While Y would contain 20 answers for these 20 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfsARLtOtcgq"
      },
      "outputs": [],
      "source": [
        "[X,y] = read_images('/content/drive/MyDrive/OpenCV/images/', 160)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp0_wBVHr-q1"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR_HlyOLUmiE"
      },
      "source": [
        "`#Always good to test it on one image to check the connectivity between Google Drive and Colab. If the test succeeds then repeat the exercise for video processing.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibmomccnx2vJ"
      },
      "outputs": [],
      "source": [
        "#cv2_imshow(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73r2zULQU7Jr"
      },
      "source": [
        "Load the h5 pre-trained model file from Google Drive. Ensure it is present at that folder or update the path in the statement below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy8PkCxavR3s"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/OpenCV/trained_model/my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yVe3u71zPce"
      },
      "outputs": [],
      "source": [
        "print(\"Total Params:\", model.count_params())\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS81p7ZzVKJ9"
      },
      "source": [
        "model.predict can be used in a loop to predict the answer for all images from test dataset. The classification after compared can go in a CSV file to record the answer for the given image.\n",
        "\n",
        "When proprocessing is needed for subsequent models then the script remains the same except for the CSV file name, and the preprocessing of image to be predicted by the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7pgeeHGvxdF",
        "outputId": "ab1e5974-a89f-4348-d73e-3559087aeeed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[-0.24773629]], dtype=float32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#predicted_labels = model.predict(X[0])\n",
        "model.predict(X[0])\n",
        "#print(\"no helmet\" if model.predict(X[0]) > 0 else \"helmet\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "2c411529d52bd385a0c5cc81dc7774bf283ab520578901012898b94c5b56fc2a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
